\hypertarget{class_position_estimator}{}\section{Position\+Estimator Class Reference}
\label{class_position_estimator}\index{Position\+Estimator@{Position\+Estimator}}


{\ttfamily \#include $<$Position\+Estimator.\+hpp$>$}

\subsection*{Public Member Functions}
\begin{DoxyCompactItemize}
\item 
\hyperlink{class_position_estimator_a162766d49cc6acd2ff0bb59737ec75c9}{Position\+Estimator} (double x, double y, double z, double pitch, double f, double pix\+\_\+density, double img\+\_\+w, double img\+\_\+h, double avg\+\_\+height)
\item 
\hyperlink{class_position_estimator_af0b8305de010b7f15f0b18499d8d50c3}{Position\+Estimator} (const std\+::unordered\+\_\+map$<$ std\+::string, double $>$ \&robot\+\_\+params)
\item 
double \hyperlink{class_position_estimator_a4af8448b844393e6320d3570868f1aaa}{approximate\+\_\+camera\+\_\+z} (const \hyperlink{struct_detection}{Detection} \&detection)
\begin{DoxyCompactList}\small\item\em This function approximates the z location of the human in the C\+A\+M\+E\+RA frame based on the size of the bounding box. \end{DoxyCompactList}\item 
std\+::array$<$ double, 3 $>$ \hyperlink{class_position_estimator_ab7aca1c0fa82d6836ae698ebe0826edd}{estimate\+\_\+xyz} (const \hyperlink{struct_detection}{Detection} \&)
\begin{DoxyCompactList}\small\item\em This method estimates the xyz position of a S\+I\+N\+G\+LE detected human in the W\+O\+R\+LD frame. \end{DoxyCompactList}\item 
std\+::shared\+\_\+ptr$<$ std\+::vector$<$ std\+::array$<$ double, 3 $>$ $>$ $>$ \hyperlink{class_position_estimator_a02dafec98e58e3354ac3abb0a5f53153}{estimate\+\_\+all\+\_\+xyz} (const std\+::vector$<$ \hyperlink{struct_detection}{Detection} $>$ \&detection)
\begin{DoxyCompactList}\small\item\em This method estimates the xyz position of E\+A\+CH detected human in the W\+O\+R\+LD frame. \end{DoxyCompactList}\item 
const Eigen\+::\+Matrix$<$ double, 4, 4 $>$ \& \hyperlink{class_position_estimator_a12ae9fe6ea2f7ca1e2054e018c5dabf5}{get\+\_\+cam2robot\+\_\+transform} ()
\begin{DoxyCompactList}\small\item\em Get the cam2robot transform object. \end{DoxyCompactList}\end{DoxyCompactItemize}


\subsection{Constructor \& Destructor Documentation}
\mbox{\Hypertarget{class_position_estimator_a162766d49cc6acd2ff0bb59737ec75c9}\label{class_position_estimator_a162766d49cc6acd2ff0bb59737ec75c9}} 
\index{Position\+Estimator@{Position\+Estimator}!Position\+Estimator@{Position\+Estimator}}
\index{Position\+Estimator@{Position\+Estimator}!Position\+Estimator@{Position\+Estimator}}
\subsubsection{\texorpdfstring{Position\+Estimator()}{PositionEstimator()}\hspace{0.1cm}{\footnotesize\ttfamily [1/2]}}
{\footnotesize\ttfamily Position\+Estimator\+::\+Position\+Estimator (\begin{DoxyParamCaption}\item[{double}]{x,  }\item[{double}]{y,  }\item[{double}]{z,  }\item[{double}]{pitch,  }\item[{double}]{f,  }\item[{double}]{pix\+\_\+density,  }\item[{double}]{img\+\_\+w,  }\item[{double}]{img\+\_\+h,  }\item[{double}]{avg\+\_\+height }\end{DoxyParamCaption})\hspace{0.3cm}{\ttfamily [inline]}}

\mbox{\Hypertarget{class_position_estimator_af0b8305de010b7f15f0b18499d8d50c3}\label{class_position_estimator_af0b8305de010b7f15f0b18499d8d50c3}} 
\index{Position\+Estimator@{Position\+Estimator}!Position\+Estimator@{Position\+Estimator}}
\index{Position\+Estimator@{Position\+Estimator}!Position\+Estimator@{Position\+Estimator}}
\subsubsection{\texorpdfstring{Position\+Estimator()}{PositionEstimator()}\hspace{0.1cm}{\footnotesize\ttfamily [2/2]}}
{\footnotesize\ttfamily Position\+Estimator\+::\+Position\+Estimator (\begin{DoxyParamCaption}\item[{const std\+::unordered\+\_\+map$<$ std\+::string, double $>$ \&}]{robot\+\_\+params }\end{DoxyParamCaption})\hspace{0.3cm}{\ttfamily [inline]}}



\subsection{Member Function Documentation}
\mbox{\Hypertarget{class_position_estimator_a4af8448b844393e6320d3570868f1aaa}\label{class_position_estimator_a4af8448b844393e6320d3570868f1aaa}} 
\index{Position\+Estimator@{Position\+Estimator}!approximate\+\_\+camera\+\_\+z@{approximate\+\_\+camera\+\_\+z}}
\index{approximate\+\_\+camera\+\_\+z@{approximate\+\_\+camera\+\_\+z}!Position\+Estimator@{Position\+Estimator}}
\subsubsection{\texorpdfstring{approximate\+\_\+camera\+\_\+z()}{approximate\_camera\_z()}}
{\footnotesize\ttfamily double Position\+Estimator\+::approximate\+\_\+camera\+\_\+z (\begin{DoxyParamCaption}\item[{const \hyperlink{struct_detection}{Detection} \&}]{detection }\end{DoxyParamCaption})}



This function approximates the z location of the human in the C\+A\+M\+E\+RA frame based on the size of the bounding box. 


\begin{DoxyParams}{Parameters}
{\em detection} & \hyperlink{struct_detection}{Detection} obj \\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
approximate depth of human in camera frame U\+N\+IT\+: \mbox{[}m\mbox{]} 
\end{DoxyReturn}
\mbox{\Hypertarget{class_position_estimator_a02dafec98e58e3354ac3abb0a5f53153}\label{class_position_estimator_a02dafec98e58e3354ac3abb0a5f53153}} 
\index{Position\+Estimator@{Position\+Estimator}!estimate\+\_\+all\+\_\+xyz@{estimate\+\_\+all\+\_\+xyz}}
\index{estimate\+\_\+all\+\_\+xyz@{estimate\+\_\+all\+\_\+xyz}!Position\+Estimator@{Position\+Estimator}}
\subsubsection{\texorpdfstring{estimate\+\_\+all\+\_\+xyz()}{estimate\_all\_xyz()}}
{\footnotesize\ttfamily std\+::shared\+\_\+ptr$<$std\+::vector$<$std\+::array$<$double, 3$>$ $>$ $>$ Position\+Estimator\+::estimate\+\_\+all\+\_\+xyz (\begin{DoxyParamCaption}\item[{const std\+::vector$<$ \hyperlink{struct_detection}{Detection} $>$ \&}]{detection }\end{DoxyParamCaption})}



This method estimates the xyz position of E\+A\+CH detected human in the W\+O\+R\+LD frame. 


\begin{DoxyParams}{Parameters}
{\em detections} & vector of \hyperlink{struct_detection}{Detection} objs \\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
std\+::shared\+\_\+ptr$<$std\+::vector$<$std\+::array$<$double, 3$>$$>$$>$\+: x, y, z position of E\+A\+CH human in R\+O\+B\+OT frame U\+N\+IT\+: \mbox{[}m\mbox{]} 
\end{DoxyReturn}
\mbox{\Hypertarget{class_position_estimator_ab7aca1c0fa82d6836ae698ebe0826edd}\label{class_position_estimator_ab7aca1c0fa82d6836ae698ebe0826edd}} 
\index{Position\+Estimator@{Position\+Estimator}!estimate\+\_\+xyz@{estimate\+\_\+xyz}}
\index{estimate\+\_\+xyz@{estimate\+\_\+xyz}!Position\+Estimator@{Position\+Estimator}}
\subsubsection{\texorpdfstring{estimate\+\_\+xyz()}{estimate\_xyz()}}
{\footnotesize\ttfamily std\+::array$<$double, 3$>$ Position\+Estimator\+::estimate\+\_\+xyz (\begin{DoxyParamCaption}\item[{const \hyperlink{struct_detection}{Detection} \&}]{ }\end{DoxyParamCaption})}



This method estimates the xyz position of a S\+I\+N\+G\+LE detected human in the W\+O\+R\+LD frame. 


\begin{DoxyParams}{Parameters}
{\em detection} & \hyperlink{struct_detection}{Detection} obj \\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
std\+::array$<$double, 3$>$\+: x, y, z position of a single human. 
\end{DoxyReturn}
\mbox{\Hypertarget{class_position_estimator_a12ae9fe6ea2f7ca1e2054e018c5dabf5}\label{class_position_estimator_a12ae9fe6ea2f7ca1e2054e018c5dabf5}} 
\index{Position\+Estimator@{Position\+Estimator}!get\+\_\+cam2robot\+\_\+transform@{get\+\_\+cam2robot\+\_\+transform}}
\index{get\+\_\+cam2robot\+\_\+transform@{get\+\_\+cam2robot\+\_\+transform}!Position\+Estimator@{Position\+Estimator}}
\subsubsection{\texorpdfstring{get\+\_\+cam2robot\+\_\+transform()}{get\_cam2robot\_transform()}}
{\footnotesize\ttfamily const Eigen\+::\+Matrix$<$double, 4, 4$>$\& Position\+Estimator\+::get\+\_\+cam2robot\+\_\+transform (\begin{DoxyParamCaption}{ }\end{DoxyParamCaption})\hspace{0.3cm}{\ttfamily [inline]}}



Get the cam2robot transform object. 

\begin{DoxyReturn}{Returns}
const Eigen\+::\+Matrix$<$double, 4, 4$>$\& 
\end{DoxyReturn}


The documentation for this class was generated from the following file\+:\begin{DoxyCompactItemize}
\item 
/media/diane/\+My Passport/\+U\+M\+D Masters/\+Fall 2021/\+E\+N\+P\+M 808\+X/\+Assignments/\+Midterm/\+A\+C\+M\+E\+\_\+perception\+\_\+proposal/include/\hyperlink{_position_estimator_8hpp}{Position\+Estimator.\+hpp}\end{DoxyCompactItemize}
